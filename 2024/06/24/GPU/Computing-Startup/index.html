

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/world.png">
  <link rel="icon" href="/img/world.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#3e424a">
  <meta name="author" content="JianliangÂ·Shen">
  <meta name="keywords" content="">
  
    <meta name="description" content="GPU, Compute and AI.">
<meta property="og:type" content="article">
<meta property="og:title" content="GPU Computing Startup">
<meta property="og:url" content="http://yoursite.com/2024/06/24/GPU/Computing-Startup/index.html">
<meta property="og:site_name" content="TechOdyssey">
<meta property="og:description" content="GPU, Compute and AI.">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://yoursite.com/img/post_pics/ai/AGI.jpeg">
<meta property="article:published_time" content="2024-06-24T23:46:14.000Z">
<meta property="article:modified_time" content="2024-07-30T16:39:00.407Z">
<meta property="article:author" content="JianliangÂ·Shen">
<meta property="article:tag" content="CUDA">
<meta property="article:tag" content="GPU">
<meta property="article:tag" content="Algorithm">
<meta property="article:tag" content="AI">
<meta property="article:tag" content="Pytorch">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://yoursite.com/img/post_pics/ai/AGI.jpeg">
  
  
  
  <title>GPU Computing Startup - TechOdyssey</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- ä¸»é¢˜ä¾èµ–çš„å›¾æ ‡åº“ï¼Œä¸è¦è‡ªè¡Œä¿®æ”¹ -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  



  
<link rel="stylesheet" href="/css/icon.css">



  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"yoursite.com","root":"/","version":"1.9.7","typing":{"enable":true,"typeSpeed":15,"cursorChar":"|","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":"â¡"},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 7.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Tech Odyssey</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>Home</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>Archives</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>Categories</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>Tags</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>About</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/links/" target="_self">
                <i class="iconfont icon-link-fill"></i>
                <span>Links</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" target="_self" href="javascript:;" role="button"
                 data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                <i class="iconfont icon-bookmark-fill"></i>
                <span>Favor</span>
              </a>
              <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                
                  
                  
                  
                  <a class="dropdown-item" href="https://vercel.com/jianliang-shens-projects" target="_self">
                    <i class="iconfont icon-vercel"></i>
                    <span>Vercel</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/pdf/" target="_self">
                    <i class="iconfont icon-pdf-new"></i>
                    <span>PDF</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="https://www.google.com/" target="_self">
                    <i class="iconfont icon-google-new"></i>
                    <span>Google</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="https://www.baidu.com/" target="_self">
                    <i class="iconfont icon-baidu-new"></i>
                    <span>Baidu</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="https://github.com/Jianliang-Shen" target="_self">
                    <i class="iconfont icon-github-new"></i>
                    <span>Github</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="https://www.zhihu.com" target="_self">
                    <i class="iconfont icon-zhihu-new"></i>
                    <span>Zhihu</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="https://www.bilibili.com/" target="_self">
                    <i class="iconfont icon-bilibili-new"></i>
                    <span>Bilibili</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="https://chat.openai.com/" target="_self">
                    <i class="iconfont icon-chatGPT"></i>
                    <span>Chatgpt</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="https://msdn.itellyou.cn/" target="_self">
                    <i class="iconfont icon-microsoft"></i>
                    <span>MSDN</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="https://www.iconfont.cn/" target="_self">
                    <i class="iconfont icon-iconfont"></i>
                    <span>Ali Icon</span>
                  </a>
                
              </div>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/back_1.jpg') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.1)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="GPU Computing Startup"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2024-06-24 23:46" pubdate>
          2024å¹´6æœˆ24æ—¥ æ™šä¸Š
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          4.6k words
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          39 mins
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">GPU Computing Startup</h1>
            
            
              <div class="markdown-body">
                
                <p>GPU, Compute and AI.</p>
<span id="more"></span>

<h2 id="ç›®å½•"><a href="#ç›®å½•" class="headerlink" title="ç›®å½•"></a>ç›®å½•</h2><ul>
<li><a href="#%E7%9B%AE%E5%BD%95">ç›®å½•</a></li>
<li><a href="#%E8%B5%84%E6%96%99%E6%B1%87%E6%80%BB">èµ„æ–™æ±‡æ€»</a></li>
<li><a href="#pytorch-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%95%B4%E7%90%86">pytorch çŸ¥è¯†ç‚¹æ•´ç†</a></li>
<li><a href="#%E5%AE%89%E8%A3%85-pytorch-cpu-%E7%89%88%E6%9C%AC">å®‰è£… pytorch cpu ç‰ˆæœ¬</a></li>
<li><a href="#%E5%AE%89%E8%A3%85-pytorch-cuda-%E7%89%88%E6%9C%AC">å®‰è£… pytorch cuda ç‰ˆæœ¬</a></li>
<li><a href="#pytorch-book-vscode-%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE">pytorch book vscode ç¯å¢ƒé…ç½®</a></li>
<li><a href="#%E7%A4%BA%E4%BE%8B">ç¤ºä¾‹</a><ul>
<li><a href="#%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92">çº¿æ€§å›å½’</a></li>
<li><a href="#fashion-mnist-%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E5%88%86%E7%B1%BB">fashion mnist æ‰‹å†™æ•°å­—åˆ†ç±»</a></li>
<li><a href="#cifar-10">cifar 10</a></li>
</ul>
</li>
</ul>
<h2 id="èµ„æ–™æ±‡æ€»"><a href="#èµ„æ–™æ±‡æ€»" class="headerlink" title="èµ„æ–™æ±‡æ€»"></a>èµ„æ–™æ±‡æ€»</h2><table>
<thead>
<tr>
<th>é“¾æ¥</th>
<th>è¯´æ˜</th>
</tr>
</thead>
<tbody><tr>
<td><a href="https://github.com/chenyuntc/pytorch-book"><strong>ã€Šæ·±åº¦å­¦ä¹ æ¡†æ¶PyTorchï¼šå…¥é—¨ä¸å®æˆ˜ã€‹ä»£ç </strong></a></td>
<td>è¿™ä¸ªé€‚åˆå¼€å§‹é˜¶æ®µï¼Œå‚è€ƒ<a href="#pytorch-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%95%B4%E7%90%86">pytorch çŸ¥è¯†ç‚¹æ•´ç†</a>ã€‚æ­¤ä¹¦é…å¥—1.6ç‰ˆæœ¬çš„pytorchï¼Œå‚è€ƒ<a href="#%E5%AE%89%E8%A3%85-pytorch-cpu-%E7%89%88%E6%9C%AC">å®‰è£… pytorch cpu ç‰ˆæœ¬</a>å’Œ<a href="#pytorch-book-vscode-%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE">pytorch book vscode ç¯å¢ƒé…ç½®</a></td>
</tr>
<tr>
<td><a href="https://pytorch.org/tutorials/beginner/basics/intro.html">Pytorch å®˜æ–¹æ–‡æ¡£</a></td>
<td>æœ€æ–°çš„æ˜¯2.3ç‰ˆæœ¬ï¼Œå’Œä¸‹é¢æ•™ç¨‹æ­é…ç€çœ‹</td>
</tr>
<tr>
<td><a href="https://github.com/pytorch/tutorials">Pytorch å®˜æ–¹æ–‡æ¡£æ•™ç¨‹ä»“åº“</a></td>
<td>PyTorch tutorialsã€‚æœ‰ç‚¹å åœ°æ–¹ï¼Œé‡Œé¢å’Œæ–‡æ¡£å†…å®¹å¯¹åº”ï¼Œæœ‰ç›´æ¥å¯è¿è¡Œçš„è„šæœ¬</td>
</tr>
<tr>
<td><a href="https://pytorch.org/get-started/locally/">Pytorch å®‰è£…æŒ‡å¼•</a></td>
<td>å®‰è£…CPU&#x2F;CUDAç‰ˆæœ¬</td>
</tr>
<tr>
<td><a href="https://github.com/apachecn/pytorch-doc-zh">Pytorch å®˜æ–¹æ–‡æ¡£ç¿»è¯‘ç‰ˆ</a></td>
<td>Pytorch ä¸­æ–‡æ–‡æ¡£ï¼Œç¼ºç‚¹ï¼Œå¹¿å‘Šå¤ªå¤š</td>
</tr>
<tr>
<td><a href="https://github.com/pytorch/examples">Pytorch Examples</a></td>
<td>å›´ç»• pytorch çš„è§†è§‰ã€æ–‡æœ¬ã€å¼ºåŒ–å­¦ä¹ ç­‰æ–¹é¢çš„ä¸€ç»„ç¤ºä¾‹ã€‚</td>
</tr>
<tr>
<td><a href="https://github.com/pytorch/pytorch">Pytorch æºç ä»“åº“</a></td>
<td>å…·æœ‰å¼ºå¤§ GPU åŠ é€Ÿçš„ Python å¼ é‡å’ŒåŠ¨æ€ç¥ç»ç½‘ç»œã€‚</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th align="center">Cuda</th>
<th align="center">Jetson åµŒå…¥å¼AI</th>
<th align="center">GPU driver</th>
</tr>
</thead>
<tbody><tr>
<td align="center"><a href="https://docs.nvidia.com/cuda/">CUDA å®˜æ–¹æ–‡æ¡£</a><br/><a href="https://docs.nvidia.com/cuda/cuda-runtime-api/index.html">CUDA Runtime API</a><br/><a href="https://github.com/NVIDIA/cuda-samples"><strong>Samples for CUDA Developers</strong></a></td>
<td align="center"><a href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-orin/"><strong>Jetson Orin</strong></a><br/><a href="https://www.jetson-ai-lab.com/tutorial-intro.html"><strong>NVIDIA Jetson AI Lab</strong></a><br/><a href="https://developer.nvidia.com/embedded/community/jetson-projects"><strong>NVIDIA Jetson-projects</strong></a><br/><a href="https://www.yahboom.com/study/Jetson-Orin-NANO"><strong>Yahboomå®˜æ–¹æ•™ç¨‹ æå–ç lguu</strong></a><br/><a href="https://developer.nvidia.com/blog/develop-ai-powered-robots-smart-vision-systems-and-more-with-nvidia-jetson-orin-nano-developer-kit">Jetson Orin Nano Developer Kit Now Available</a></td>
<td align="center"><a href="https://github.com/NVIDIA/open-gpu-kernel-modules"><strong>NVIDIA GPU Kernel Modules</strong></a><br/><a href="https://github.com/torvalds/linux/tree/master/drivers/gpu/drm/amd/amdgpu">AMD KMD Driver in Linux</a></td>
</tr>
</tbody></table>

    <div class="fold">
      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-1e33e29d" role="button" aria-expanded="false" aria-controls="collapse-1e33e29d">
        <div class="fold-arrow">â–¶</div>Github èµ„æºæ±‡æ€»
      </div>
      <div class="fold-collapse collapse" id="collapse-1e33e29d">
        <div class="fold-content">
          <table><thead><tr><th align="center">ä»“åº“</th><th>è¯´æ˜</th></tr></thead><tbody><tr><td align="center"><strong>1. AI&#x2F;AGI&#x2F;AIoT</strong></td><td></td></tr><tr><td align="center"><a href="https://github.com/huggingface/transformers"><strong>HuggingFace&#x2F;Transformers<br/>â˜…â˜…â˜…â˜…â˜…</strong></a></td><td>è‘—åè®ºæ–‡<a href="https://arxiv.org/abs/1706.03762">Attention Is All You Need</a> æå‡ºçš„ Transformers  æä¾›æ•°åƒä¸ªé¢„è®­ç»ƒæ¨¡å‹ï¼Œç”¨äºæ‰§è¡Œä¸åŒæ¨¡æ€ï¼ˆä¾‹å¦‚æ–‡æœ¬ã€è§†è§‰å’ŒéŸ³é¢‘ï¼‰çš„ä»»åŠ¡ã€‚è¿™äº›æ¨¡å‹å¯åº”ç”¨äºï¼š<br/>1. ğŸ“ æ–‡æœ¬ï¼Œç”¨äº 100 å¤šç§è¯­è¨€çš„æ–‡æœ¬åˆ†ç±»ã€ä¿¡æ¯æå–ã€é—®ç­”ã€æ‘˜è¦ã€ç¿»è¯‘å’Œæ–‡æœ¬ç”Ÿæˆç­‰ä»»åŠ¡ã€‚<br/>2. ğŸ–¼ï¸ å›¾åƒï¼Œç”¨äºå›¾åƒåˆ†ç±»ã€å¯¹è±¡æ£€æµ‹å’Œåˆ†å‰²ç­‰ä»»åŠ¡ã€‚<br/>3. ğŸ—£ï¸ éŸ³é¢‘ï¼Œç”¨äºè¯­éŸ³è¯†åˆ«å’ŒéŸ³é¢‘åˆ†ç±»ç­‰ä»»åŠ¡ã€‚<br/>Transformers æ¨¡å‹è¿˜å¯ä»¥æ‰§è¡Œå¤šç§æ¨¡æ€ç»„åˆçš„ä»»åŠ¡ï¼Œä¾‹å¦‚è¡¨æ ¼é—®ç­”ã€å…‰å­¦å­—ç¬¦è¯†åˆ«ã€ä»æ‰«ææ–‡æ¡£ä¸­æå–ä¿¡æ¯ã€è§†é¢‘åˆ†ç±»å’Œè§†è§‰é—®ç­”ã€‚</td></tr><tr><td align="center"><a href="https://github.com/karpathy/llm.c"><strong>Karpathy&#x2F;llm.c<br/>â˜…â˜…â˜…â˜…â˜…</strong></a></td><td>ç®€å•ã€çº¯ C&#x2F;CUDA çš„ LLMï¼Œæ— éœ€ 245MB çš„ PyTorch æˆ– 107MB çš„ cPythonã€‚å½“å‰é‡ç‚¹æ˜¯é¢„è®­ç»ƒï¼Œç‰¹åˆ«æ˜¯é‡ç° GPT-2 å’Œ GPT-3 è¿·ä½ å‰§ï¼Œä»¥åŠ train_gpt2.py ä¸­çš„å¹¶è¡Œ PyTorch å‚è€ƒå®ç°ã€‚æµ‹è¯•è§ï¼š<a href="http://jianliang-shen.cn/2024/04/28/llm.c/">llm.c</a></td></tr><tr><td align="center"><a href="https://github.com/google-research/vision_transformer"><strong>Google&#x2F;Vision Transformer<br/>â˜…â˜…â˜…â˜…â˜…</strong></a></td><td>åœ¨è¿™ä¸ªå­˜å‚¨åº“ä¸­ï¼Œæˆ‘ä»¬å‘å¸ƒäº†è®ºæ–‡ä¸­çš„æ¨¡å‹<br/>ä¸€å¼ å›¾ç‰‡èƒœè¿‡ 16x16 ä¸ªå•è¯ï¼šç”¨äºå¤§è§„æ¨¡å›¾åƒè¯†åˆ«çš„ Transformers<br/>MLP-Mixerï¼šç”¨äºè§†è§‰çš„å…¨ MLP æ¶æ„<br/>å¦‚ä½•è®­ç»ƒä½ çš„ ViTï¼Ÿè§†è§‰ Transformers ä¸­çš„æ•°æ®ã€å¢å¼ºå’Œæ­£åˆ™åŒ–<br/>å½“è§†è§‰ Transformers åœ¨æ²¡æœ‰é¢„è®­ç»ƒæˆ–å¼ºå¤§çš„æ•°æ®å¢å¼ºçš„æƒ…å†µä¸‹èƒœè¿‡ ResNets æ—¶<br/>LiTï¼šä½¿ç”¨é”å®šå›¾åƒæ–‡æœ¬è°ƒæ•´çš„é›¶æ ·æœ¬ä¼ è¾“<br/>æ›¿ä»£é—´éš™æœ€å°åŒ–æ”¹è¿›äº†æ¸…æ™°åº¦æ„ŸçŸ¥è®­ç»ƒ<br/>è¿™äº›æ¨¡å‹åœ¨ ImageNet å’Œ ImageNet-21k æ•°æ®é›†ä¸Šè¿›è¡Œäº†é¢„è®­ç»ƒã€‚æˆ‘ä»¬åœ¨ JAX&#x2F;Flax ä¸­æä¾›äº†ç”¨äºå¾®è°ƒå·²å‘å¸ƒæ¨¡å‹çš„ä»£ç ã€‚<br/></td></tr><tr><td align="center"><a href="https://github.com/ultralytics/yolov5"><strong>Ultralytics&#x2F;Yolov5<br/>â˜…â˜…â˜…â˜…â˜…</strong></a></td><td>YOLOv5ğŸš€æ˜¯ä¸–ç•Œä¸Šæœ€å—æ¬¢è¿çš„è§†è§‰ AIï¼Œä»£è¡¨äº† Ultralytics å¯¹æœªæ¥è§†è§‰ AI æ–¹æ³•çš„å¼€æºç ”ç©¶ï¼Œèåˆäº†æ•°åƒå°æ—¶ç ”å‘è¿‡ç¨‹ä¸­è·å¾—çš„ç»éªŒæ•™è®­å’Œæœ€ä½³å®è·µã€‚</td></tr><tr><td align="center"><a href="https://github.com/dusty-nv/jetson-inference"><strong>Dusty-nv&#x2F;Jetson Inference<br/>â˜…â˜…â˜…â˜…â˜…</strong></a></td><td>è¯¥é¡¹ç›®ä½¿ç”¨ TensorRT åœ¨ C++ æˆ– Python çš„ GPU ä¸Šè¿è¡Œä¼˜åŒ–ç½‘ç»œï¼Œå¹¶ä½¿ç”¨ PyTorch è®­ç»ƒæ¨¡å‹ã€‚æ”¯æŒçš„ DNN è§†è§‰åŸºå…ƒåŒ…æ‹¬ç”¨äºå›¾åƒåˆ†ç±»çš„ imageNetã€ç”¨äºå¯¹è±¡æ£€æµ‹çš„ detectNetã€ç”¨äºè¯­ä¹‰åˆ†å‰²çš„ segNetã€ç”¨äºå§¿åŠ¿ä¼°è®¡çš„ poseNet å’Œç”¨äºåŠ¨ä½œè¯†åˆ«çš„ actionNetã€‚æä¾›äº†ä»å®æ—¶æ‘„åƒå¤´æºè¿›è¡Œæµå¼ä¼ è¾“ã€ä½¿ç”¨ WebRTC åˆ¶ä½œ Web åº”ç”¨ç¨‹åºä»¥åŠå¯¹ ROS&#x2F;ROS2 çš„æ”¯æŒçš„ç¤ºä¾‹ã€‚</td></tr><tr><td align="center"><a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui"><strong>Stable Diffusion WebUI<br/>â˜…â˜…â˜…â˜…â˜…</strong></a></td><td>ä½¿ç”¨ Gradio åº“å®ç°çš„Stable Diffusionçš„ Web ç•Œé¢ã€‚ <a href="https://github.com/dtlnor/stable-diffusion-webui-localization-zh_CN">ç®€ä½“ä¸­æ–‡ç¿»è¯‘æ‰©å±•</a></td></tr><tr><td align="center"><a href="https://github.com/Zhouyi-AIPU/Model_zoo"><strong>Zhouyi-AIPU&#x2F;Model Zoo<br/>â˜…â˜…â˜…</strong></a></td><td>å„ç§Embedded modelæ±‡æ€»</td></tr><tr><td align="center"><a href="https://github.com/huggingface/pytorch-image-models">HuggingFace&#x2F;Pytorch image models<br/>â˜…</a></td><td>æœ€å¤§çš„ PyTorch å›¾åƒ encoders &#x2F; backbone é›†åˆã€‚åŒ…æ‹¬è®­ç»ƒã€è¯„ä¼°ã€æ¨ç†ã€å¯¼å‡ºè„šæœ¬å’Œé¢„è®­ç»ƒæƒé‡ - ResNetã€ResNeXTã€EfficientNetã€NFNetã€Vision Transformer (ViT)ã€MobileNetV4ã€MobileNet-V3 &amp; V2ã€RegNetã€DPNã€CSPNetã€Swin Transformerã€MaxViTã€CoAtNetã€ConvNeXt ç­‰</td></tr><tr><td align="center"><a href="https://github.com/huggingface/datasets">HuggingFace&#x2F;Datasets<br/>â˜…</a></td><td>Datasets æ˜¯ä¸€ä¸ªè½»é‡çº§åº“ï¼Œæä¾›ä¸¤ä¸ªä¸»è¦åŠŸèƒ½ï¼šé€‚ç”¨äºè®¸å¤šå…¬å…±æ•°æ®é›†çš„å•è¡Œæ•°æ®åŠ è½½å™¨ï¼›é«˜æ•ˆçš„æ•°æ®é¢„å¤„ç†ã€‚</td></tr><tr><td align="center"><a href="https://github.com/huggingface/accelerate">HuggingFace&#x2F;Accelerate<br/>â˜…</a></td><td>Accelerate æ˜¯ä¸ºé‚£äº›å–œæ¬¢ç¼–å†™ PyTorch æ¨¡å‹è®­ç»ƒå¾ªç¯ä½†ä¸æ„¿æ„ç¼–å†™å’Œç»´æŠ¤ä½¿ç”¨å¤š GPU&#x2F;TPU&#x2F;fp16 æ‰€éœ€çš„æ ·æ¿ä»£ç çš„ PyTorch ç”¨æˆ·åˆ›å»ºçš„ã€‚</td></tr><tr><td align="center"><a href="https://github.com/Stability-AI/generative-models">Stability-AI&#x2F;Generative Models<br/>â˜…</a></td><td>Generative Models by Stability AI</td></tr><tr><td align="center"><a href="https://github.com/Stability-AI/stablediffusion">Stability-AI&#x2F;Stable Diffusion<br/>â˜…</a></td><td>æ­¤å­˜å‚¨åº“åŒ…å«ä»å¤´å¼€å§‹è®­ç»ƒçš„ Stable Diffusion æ¨¡å‹ï¼Œå¹¶å°†ä½¿ç”¨æ–°çš„æ£€æŸ¥ç‚¹ä¸æ–­æ›´æ–°ã€‚</td></tr><tr><td align="center"><a href="https://github.com/tensorflow/tensorflow">TensorFlow<br/>â˜…</a></td><td>An Open Source Machine Learning Framework for Everyone</td></tr><tr><td align="center"><a href="https://github.com/tensorflow/models">TensorFlow Models<br/>â˜…</a></td><td>Models and examples built with TensorFlow</td></tr><tr><td align="center"><a href="https://github.com/ultralytics/ultralytics">Ultralytics&#x2F;ultralytics<br/>â˜…</a></td><td>Ultralytics YOLOv8 æ˜¯ä¸€æ¬¾å°–ç«¯çš„ã€æœ€å…ˆè¿›çš„ (SOTA) æ¨¡å‹ï¼Œå®ƒä»¥ä¹‹å‰ YOLO ç‰ˆæœ¬çš„æˆåŠŸä¸ºåŸºç¡€ï¼Œå¹¶å¼•å…¥äº†æ–°åŠŸèƒ½å’Œæ”¹è¿›ï¼Œä»¥è¿›ä¸€æ­¥æé«˜æ€§èƒ½å’Œçµæ´»æ€§ã€‚YOLOv8 æ—¨åœ¨å¿«é€Ÿã€å‡†ç¡®ä¸”æ˜“äºä½¿ç”¨ï¼Œä½¿å…¶æˆä¸ºå„ç§å¯¹è±¡æ£€æµ‹å’Œè·Ÿè¸ªã€å®ä¾‹åˆ†å‰²ã€å›¾åƒåˆ†ç±»å’Œå§¿åŠ¿ä¼°è®¡ä»»åŠ¡çš„ç»ä½³é€‰æ‹©ã€‚</td></tr><tr><td align="center"><a href="https://github.com/karpathy/llama2.c">Karpathy&#x2F;llama2.c<br/>â˜…</a></td><td>åœ¨ PyTorch ä¸­è®­ç»ƒ Llama 2 LLM æ¶æ„ï¼Œç„¶åä½¿ç”¨ä¸€ä¸ªç®€å•çš„ 700 è¡Œ C æ–‡ä»¶ (run.c) è¿›è¡Œæ¨ç†ã€‚</td></tr><tr><td align="center"><a href="https://github.com/Morizeyao/GPT2-Chinese">GPT2-Chinese<br/>â˜…</a></td><td>ä¸­æ–‡çš„GPT2è®­ç»ƒä»£ç ï¼Œä½¿ç”¨BERTçš„Tokenizeræˆ–Sentencepieceçš„BPE model</td></tr><tr><td align="center"><a href="https://github.com/openai/openai-cookbook">openai-cookbook<br/>â˜…â˜…</a></td><td>ä½¿ç”¨ OpenAI API å®Œæˆå¸¸è§ä»»åŠ¡çš„ç¤ºä¾‹ä»£ç å’ŒæŒ‡å—ã€‚</td></tr><tr><td align="center"><a href="https://github.com/onnx/onnx">ONNX<br/>â˜…â˜…â˜…</a></td><td>å¼€æ”¾ç¥ç»ç½‘ç»œäº¤æ¢(ONNX)æ˜¯ä¸€ä¸ªå¼€æ”¾çš„ç”Ÿæ€ç³»ç»Ÿï¼Œä½¿äººå·¥æ™ºèƒ½å¼€å‘äººå‘˜èƒ½å¤Ÿéšç€é¡¹ç›®çš„å‘å±•é€‰æ‹©åˆé€‚çš„å·¥å…·ã€‚ONNXä¸ºäººå·¥æ™ºèƒ½æ¨¡å‹æä¾›äº†ä¸€ç§å¼€æºæ ¼å¼ï¼ŒåŒ…æ‹¬æ·±åº¦å­¦ä¹ å’Œä¼ ç»ŸMLï¼Œå®ƒå®šä¹‰äº†ä¸€ä¸ªå¯æ‰©å±•çš„è®¡ç®—å›¾æ¨¡å‹ï¼Œä»¥åŠå†…ç½®è¿ç®—ç¬¦å’Œæ ‡å‡†æ•°æ®ç±»å‹çš„å®šä¹‰ã€‚ç›®å‰æˆ‘ä»¬ä¸“æ³¨äºæ¨ç†(è¯„åˆ†)æ‰€éœ€çš„åŠŸèƒ½ã€‚</td></tr><tr><td align="center"><a href="https://github.com/microsoft/onnxruntime">Microsoft&#x2F;ONNX Runtime<br/>â˜…</a></td><td>ONNX Runtime æ˜¯ä¸€ä¸ªè·¨å¹³å°æ¨ç†å’Œè®­ç»ƒæœºå™¨å­¦ä¹ åŠ é€Ÿå™¨ã€‚</td></tr><tr><td align="center"><a href="https://github.com/onnx/onnx-tensorrt">onnx-tensorrt<br/>â˜…â˜…</a></td><td>è§£æ ONNX æ¨¡å‹ä»¥ä¾¿ä½¿ç”¨ <a href="https://developer.nvidia.com/tensorrt">TensorRT</a> æ‰§è¡Œã€‚ NVIDIAÂ® TensorRTâ„¢ æ˜¯ä¸€ä¸ªç”¨äºé«˜æ€§èƒ½æ·±åº¦å­¦ä¹ æ¨ç†çš„ API ç”Ÿæ€ç³»ç»Ÿã€‚TensorRT åŒ…æ‹¬æ¨ç†è¿è¡Œæ—¶å’Œæ¨¡å‹ä¼˜åŒ–ï¼Œå¯ä¸ºç”Ÿäº§åº”ç”¨ç¨‹åºæä¾›ä½å»¶è¿Ÿå’Œé«˜ååé‡ã€‚TensorRT ç”Ÿæ€ç³»ç»ŸåŒ…æ‹¬ TensorRTã€TensorRT-LLMã€TensorRT æ¨¡å‹ä¼˜åŒ–å™¨å’Œ TensorRT Cloudã€‚</td></tr><tr><td align="center"><a href="https://github.com/daquexian/onnx-simplifier">onnx-simplifier<br/>â˜…</a></td><td>ONNX å¾ˆæ£’ï¼Œä½†æœ‰æ—¶å¤ªå¤æ‚ã€‚</td></tr><tr><td align="center"><a href="https://github.com/onnx/tensorflow-onnx">tensorflow-onnx<br/>â˜…</a></td><td>tf2onnx é€šè¿‡å‘½ä»¤è¡Œæˆ– python api å°† TensorFlowï¼ˆtf-1.x æˆ– tf-2.xï¼‰ã€kerasã€tensorflow.js å’Œ tflite æ¨¡å‹è½¬æ¢ä¸º ONNXã€‚</td></tr><tr><td align="center"><strong>2. GPU&#x2F;CUDA&#x2F;Rocm</strong></td><td></td></tr><tr><td align="center"><a href="https://github.com/DefTruth/CUDA-Learn-Notes"><strong>CUDA-Learn-Notes<br/>â˜…â˜…â˜…â˜…â˜…</strong></a></td><td>CUDA-Learn-Notes: CUDA ç¬”è®°ã€å¤§æ¨¡å‹æ‰‹æ’•CUDAã€C++ç¬”è®°</td></tr><tr><td align="center"><a href="https://github.com/HeKun-NVIDIA/CUDA-Programming-Guide-in-Chinese"><strong>CUDA-Programming-Guide-in-Chinese<br/>â˜…</strong></a></td><td>æœ¬é¡¹ç›®ä¸º CUDA C Programming Guide çš„ä¸­æ–‡ç¿»è¯‘ç‰ˆã€‚</td></tr><tr><td align="center"><a href="https://github.com/godweiyang/NN-CUDA-Example">NN-CUDA-Example<br/>â˜…</a></td><td>è°ƒç”¨è‡ªå®šä¹‰ CUDA è¿ç®—ç¬¦çš„ç¥ç»ç½‘ç»œå·¥å…·åŒ…ï¼ˆPyTorchã€TensorFlow ç­‰ï¼‰çš„å‡ ä¸ªç®€å•ç¤ºä¾‹ã€‚</td></tr><tr><td align="center"><a href="https://github.com/NVIDIA/nvtrust">NVTrust<br/>â˜…</a></td><td>nvTrust æ˜¯ä¸€ä¸ªå­˜å‚¨åº“ï¼Œå…¶ä¸­åŒ…å«åœ¨å—ä¿¡ä»»çš„ç¯å¢ƒï¼ˆä¾‹å¦‚æœºå¯†è®¡ç®—ï¼‰ä¸­ä½¿ç”¨ NVIDIA è§£å†³æ–¹æ¡ˆæ—¶åˆ©ç”¨çš„è®¸å¤šå®ç”¨ç¨‹åºå’Œå·¥å…·ã€å¼€æºä»£ç å’Œ SDKã€‚</td></tr><tr><td align="center"><a href="https://github.com/protectai/llm-guard">LLM Guard</a></td><td>LLM äº¤äº’çš„å®‰å…¨å·¥å…·åŒ…</td></tr><tr><td align="center"><a href="https://github.com/ROCm/ROCT-Thunk-Interface">ROCm&#x2F;ROCT-Thunk-Interface<br/>â˜…</a></td><td>æ­¤å­˜å‚¨åº“åŒ…å«ç”¨äºä¸ (AMD)ROCk é©±åŠ¨ç¨‹åºäº¤äº’çš„ç”¨æˆ·æ¨¡å¼ â€‹â€‹API æ¥å£ã€‚</td></tr><tr><td align="center"><strong>3. å…è´¹èµ„æº</strong></td><td></td></tr><tr><td align="center"><a href="https://github.com/GrowingGit/GitHub-Chinese-Top-Charts"><strong>GitHubä¸­æ–‡å¼€æºä»“åº“æ’è¡Œæ¦œ<br/>â˜…â˜…â˜…â˜…â˜…</strong></a></td><td>GitHubä¸­æ–‡æ’è¡Œæ¦œï¼Œå¸®åŠ©ä½ å‘ç°ä¼˜ç§€ä¸­æ–‡é¡¹ç›®ï¼Œå¯ä»¥æ— è¯­è¨€éšœç¢åœ°ã€æ›´é«˜æ•ˆåœ°å¸æ”¶ä¼˜ç§€ç»éªŒæˆæœ</td></tr><tr><td align="center"><a href="https://github.com/EbookFoundation/free-programming-books"><strong>free-programming-books<br/>â˜…â˜…â˜…â˜…â˜…</strong></a></td><td>å¤šç§è¯­è¨€çš„å…è´¹å­¦ä¹ èµ„æºåˆ—è¡¨</td></tr><tr><td align="center"><a href="https://github.com/forthespada/CS-Books">CS EBook<br/>â˜…â˜…â˜…</a></td><td>è¶…è¿‡1000æœ¬çš„è®¡ç®—æœºç»å…¸ä¹¦ç±åˆ†äº«ï¼Œè§£å‹å¯†ç ï¼ša123654</td></tr><tr><td align="center"><a href="https://github.com/lining808/CS-Ebook">CS EBook<br/>â˜…â˜…â˜…</a></td><td>æœ¬å‚¨å­˜åº“æ˜¯ä¸€äº›é«˜è´¨é‡çš„è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯ä¹¦ç±æ¨èä¹¦å•ï¼Œéœ€è¦å­¦ä¹ çš„å¯ä»¥æŒ‰ç…§æ­¤ä¹¦å•è¿›è¡Œå­¦ä¹ è¿›é˜¶ï¼ŒåŒ…å«äº†è®¡ç®—æœºå¤§å¤šæ•°è½¯ä»¶ç›¸å…³æ–¹å‘ã€‚è€Œä¸”æ•¢æ‰¿è¯ºä¸€ç›´æ›´æ–°ã€‚</td></tr><tr><td align="center"><a href="https://github.com/zhoucz97/myLearning">zhoucz97&#x2F;myLearning</a></td><td>è®°å½•ä¸ªäººçš„å­¦ä¹ å†ç¨‹ã€‚åŒ…æ‹¬ä½†ä¸é™äºç®—æ³•ã€æœºå™¨å­¦ä¹ ã€è®ºæ–‡å†™ä½œç­‰ã€‚</td></tr></tbody></table>
        </div>
      </div>
    </div>


    <div class="fold">
      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-a44f8816" role="button" aria-expanded="false" aria-controls="collapse-a44f8816">
        <div class="fold-arrow">â–¶</div>PyTorchæ–‡æ¡£
      </div>
      <div class="fold-collapse collapse" id="collapse-a44f8816">
        <div class="fold-content">
          <iframe src="https://pytorch.org/tutorials/beginner/basics/intro.html" width="100%" height="800" name="topFrame" scrolling="yes"  noresize="noresize" frameborder="0" id="topFrame"></iframe>
        </div>
      </div>
    </div>


    <div class="fold">
      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-4348e078" role="button" aria-expanded="false" aria-controls="collapse-4348e078">
        <div class="fold-arrow">â–¶</div>CUDAæ–‡æ¡£
      </div>
      <div class="fold-collapse collapse" id="collapse-4348e078">
        <div class="fold-content">
          <iframe src="https://docs.nvidia.com/cuda/" width="100%" height="800" name="topFrame" scrolling="yes"  noresize="noresize" frameborder="0" id="topFrame"></iframe>
        </div>
      </div>
    </div>

<h2 id="pytorch-çŸ¥è¯†ç‚¹æ•´ç†"><a href="#pytorch-çŸ¥è¯†ç‚¹æ•´ç†" class="headerlink" title="pytorch çŸ¥è¯†ç‚¹æ•´ç†"></a>pytorch çŸ¥è¯†ç‚¹æ•´ç†</h2><p>ã€Šæ·±åº¦å­¦ä¹ æ¡†æ¶ PyTorch: å…¥é—¨ä¸å®æˆ˜ã€‹</p>

    <div class="fold">
      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-13aa53af" role="button" aria-expanded="false" aria-controls="collapse-13aa53af">
        <div class="fold-arrow">â–¶</div>Chapter 2, ç®€å•ä»‹ç» tensor å’Œæ„å»º cifar-10 è®­ç»ƒæ¨¡å‹
      </div>
      <div class="fold-collapse collapse" id="collapse-13aa53af">
        <div class="fold-content">
          <ul><li>å®‰è£…Pytorch</li><li>åŸºæœ¬æ“ä½œï¼Œå¦‚catç­‰</li><li>å‡†å¤‡ä¸€ä¸ªcifar-10æ¨¡å‹ï¼Œå¹¶è®­ç»ƒæ¨ç†</li></ul>
        </div>
      </div>
    </div>


    <div class="fold">
      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-898f91ec" role="button" aria-expanded="false" aria-controls="collapse-898f91ec">
        <div class="fold-arrow">â–¶</div>Chapter 3, ä»‹ç» tensor
      </div>
      <div class="fold-collapse collapse" id="collapse-898f91ec">
        <div class="fold-content">
          <table><thead><tr><th>æ¦‚è¦</th><th>å†…å®¹</th></tr></thead><tbody><tr><td>åŸºæœ¬æ“ä½œ</td><td>Tensor(*sizes), tensor(data)<br/>ones&#x2F;zeros&#x2F;eye(*sizes)<br/>arrange(start, end, step), linspace(start, end, steps)<br/>rand &#x2F; randn(*sizes)<br/>new_* &#x2F; *_like()</td></tr><tr><td>å‘½åå¼ é‡</td><td>names, refine_names, rename, align_to</td></tr><tr><td>ç±»å‹</td><td>set_default_tensor_type, type(new_type) &#x3D;&#x3D; .float(), .long(), .half(), to(device)</td></tr><tr><td>ç´¢å¼•</td><td>index_select(input, dim, index)<br/>masked_select(input, mask)<br/>gather(input, dim, index)<br/>input.scatter_(dim, index)æ”¾å›<br/>non_zero(input)éé›¶ä¸‹æ ‡</td></tr><tr><td>å…ƒç´ æ“ä½œ</td><td>abs&#x2F;sqrt&#x2F;div&#x2F;exp&#x2F;fmod&#x2F;log&#x2F;pow, cos&#x2F;sin&#x2F;asin&#x2F;atan2&#x2F;cosh, ceil&#x2F;round&#x2F;floor&#x2F;trunc, clamp(input,min,max), sigmod&#x2F;tanh, cumsum&#x2F;cumprod</td></tr><tr><td>å½’å¹¶æ“ä½œ</td><td>mean&#x2F;sum&#x2F;median&#x2F;mode, norm&#x2F;dist, std&#x2F;var, keepdim&#x3D;True<br/>ä¿ç•™ç»´åº¦, åœ¨å“ªä¸ªç»´åº¦æ“ä½œ, å“ªä¸ªç»´åº¦å˜æˆ1ï¼Œæˆ–è€…æ¶ˆå¤±</td></tr><tr><td>æ¯”è¾ƒ</td><td>gt&#x2F;lt&#x2F;ge&#x2F;le&#x2F;eq&#x2F;ne, topk, sort, max&#x2F;min</td></tr><tr><td>çº¿æ€§ä»£æ•°</td><td>trace, diag, triu&#x2F;tril, mm&#x2F;bmm, addmm&#x2F;addbmm&#x2F;addmv, t, dot&#x2F;cross, inverse, svd</td></tr><tr><td>Numpy</td><td>from_numpyï¼Œå…±äº«å†…å­˜<br/>torch.tensor()åªè¿›è¡Œæ•°æ®æ‹·è´, ä¸ä¼šå…±äº«å†…å­˜<br/>torch.Tensor()åœ¨ç±»å‹ä¸ä¸€è‡´æ—¶æ˜¯å¤åˆ¶è€Œéå…±äº«å†…å­˜</td></tr><tr><td>TensoråŸºæœ¬ç»“æ„</td><td>storage()æŸ¥çœ‹æ˜¯å¦å…±äº«, contiguous()å˜æˆè¿ç»­</td></tr><tr><td>Tensoræ”¹å˜å½¢çŠ¶</td><td>æŸ¥çœ‹ä¿¡æ¯, size() &#x3D; shape, dim() &#x3D; len(tensor.shape), numel &lt;&#x3D;&gt; numpy.size<br/>æ”¹å˜ç»´åº¦, reshape(), view(), view_as()<br/>å¢åŠ å‡å°‘ç»´åº¦, squeeze()å‹ç¼©, unsqueeze()æ–°å»ºç»´åº¦, flatten(start_dim, end_dim)<br/>è½¬ç½®, transpose()ä»…é™äºŒç»´, t(), T, permute()</td></tr><tr><td>çº¿æ€§å›å½’å®ä¾‹</td><td>æ‰‹åŠ¨è®¡ç®—æ±‚å¯¼å‡½æ•°</td></tr><tr><td>autograd</td><td>requires_grad&#x3D;True, retain_graph&#x3D;None, is_leaf, backward()</td></tr><tr><td>ç”¨autogradå®ç°çº¿æ€§å›å½’</td><td>è‡ªåŠ¨backward, æ¢¯åº¦ä¸‹é™</td></tr></tbody></table>
        </div>
      </div>
    </div>


    <div class="fold">
      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-35d00b6d" role="button" aria-expanded="false" aria-controls="collapse-35d00b6d">
        <div class="fold-arrow">â–¶</div>Chapter 4, ç¥ç»ç½‘ç»œå·¥å…·ç®±nn
      </div>
      <div class="fold-collapse collapse" id="collapse-35d00b6d">
        <div class="fold-content">
          <p>torch.nnæ˜¯ä¸“é—¨ä¸ºæ·±åº¦å­¦ä¹ è€Œè®¾è®¡çš„æ¨¡å—ã€‚torch.nnçš„æ ¸å¿ƒæ•°æ®ç»“æ„æ˜¯<code>Module</code>ï¼Œå®ƒæ˜¯ä¸€ä¸ªæŠ½è±¡çš„æ¦‚å¿µï¼Œæ—¢å¯ä»¥è¡¨ç¤ºç¥ç»ç½‘ç»œä¸­çš„æŸä¸ªå±‚ï¼ˆlayerï¼‰ï¼Œä¹Ÿå¯ä»¥è¡¨ç¤ºä¸€ä¸ªåŒ…å«å¾ˆå¤šå±‚çš„ç¥ç»ç½‘ç»œã€‚åœ¨å®é™…ä½¿ç”¨ä¸­ï¼Œæœ€å¸¸è§çš„åšæ³•æ˜¯ç»§æ‰¿<code>nn.Module</code>ï¼Œä»è€Œç¼–å†™è‡ªå·±çš„ç½‘ç»œ&#x2F;å±‚ã€‚å¤šå±‚æ„ŸçŸ¥æœºçš„ç½‘ç»œç»“æ„å¦‚å›¾æ‰€ç¤ºï¼Œå®ƒç”±ä¸¤ä¸ªå…¨è¿æ¥å±‚ç»„æˆï¼Œé‡‡ç”¨$sigmoid$å‡½æ•°ä½œä¸ºæ¿€æ´»å‡½æ•°ï¼ˆå›¾ä¸­æ²¡æœ‰ç”»å‡ºï¼‰ã€‚</p><p><img src="/img/post_pics/ai/multi_perceptron.png" srcset="/img/loading.gif" lazyload alt="ç¥ç»ç½‘ç»œ"></p><p>PyTorchå†…éƒ¨å®ç°äº†ç¥ç»ç½‘ç»œä¸­ç»å¤§å¤šæ•°çš„layerï¼Œè¿™äº›layeréƒ½ç»§æ‰¿äº<code>nn.Module</code>ï¼Œå°è£…äº†å¯å­¦ä¹ å‚æ•°<code>parameter</code>ï¼Œå¹¶å®ç°äº†<code>forward</code>å‡½æ•°ã€‚åŒæ—¶ï¼Œå¤§éƒ¨åˆ†layeréƒ½ä¸“é—¨é’ˆå¯¹GPUè¿ç®—è¿›è¡Œäº†CuDNNä¼˜åŒ–ï¼Œå…¶é€Ÿåº¦å’Œæ€§èƒ½éƒ½ååˆ†ä¼˜å¼‚ã€‚å…³æ³¨æ¯ä¸€å±‚çš„ä¿¡æ¯æœ‰ï¼š</p><ol><li>æ„é€ å‡½æ•°çš„å‚æ•°ï¼Œå¦‚nn.Linear(in_features, out_features, bias)ï¼Œéœ€å…³æ³¨è¿™ä¸‰ä¸ªå‚æ•°çš„ä½œç”¨ï¼›</li><li>å±æ€§ã€å¯å­¦ä¹ å‚æ•°å’Œå­moduleã€‚å¦‚nn.Linearä¸­æœ‰<code>weight</code>å’Œ<code>bias</code>ä¸¤ä¸ªå¯å­¦ä¹ å‚æ•°ï¼Œä¸åŒ…å«å­moduleï¼›</li><li>è¾“å…¥è¾“å‡ºçš„å½¢çŠ¶ï¼Œå¦‚nn.linearçš„è¾“å…¥å½¢çŠ¶æ˜¯(N, input_features)ï¼Œè¾“å‡ºä¸º(Nï¼Œoutput_features)ï¼Œå…¶ä¸­Næ˜¯batch_sizeã€‚</li></ol><p>å›¾åƒnnåŒ…æ‹¬ï¼Œå·ç§¯å±‚ï¼ˆConvï¼‰ã€æ± åŒ–å±‚ï¼ˆPoolï¼‰ï¼Œæ± åŒ–æ–¹å¼åˆåˆ†ä¸ºå¹³å‡æ± åŒ–ï¼ˆAvgPoolï¼‰ã€æœ€å¤§å€¼æ± åŒ–ï¼ˆMaxPoolï¼‰ã€è‡ªé€‚åº”æ± åŒ–ï¼ˆAdaptiveAvgPoolï¼‰ç­‰ã€‚è€Œå·ç§¯å±‚é™¤äº†å¸¸ç”¨çš„å‰å‘å·ç§¯ä¹‹å¤–ï¼Œè¿˜æœ‰é€†å·ç§¯ï¼ˆTransposeConvï¼‰ã€‚å·ç§¯ç¥ç»ç½‘ç»œçš„æœ¬è´¨å°±æ˜¯å·ç§¯å±‚ã€æ± åŒ–å±‚ã€æ¿€æ´»å±‚ä»¥åŠå…¶ä»–å±‚çš„å åŠ ã€‚æ± åŒ–å±‚å¯ä»¥çœ‹ä½œæ˜¯ä¸€ç§ç‰¹æ®Šçš„å·ç§¯å±‚ï¼Œå…¶ä¸»è¦ç”¨äºä¸‹é‡‡æ ·ï¼Œå¢åŠ æ± åŒ–å±‚å¯ä»¥åœ¨ä¿ç•™ä¸»è¦ç‰¹å¾çš„åŒæ—¶é™ä½å‚æ•°é‡ï¼Œä»è€Œä¸€å®šç¨‹åº¦ä¸Šé˜²æ­¢äº†è¿‡æ‹Ÿåˆã€‚æ± åŒ–å±‚æ²¡æœ‰å¯å­¦ä¹ å‚æ•°ï¼Œå®ƒçš„weightæ˜¯å›ºå®šçš„ã€‚åœ¨<code>torch.nn</code>å·¥å…·ç®±ä¸­å°è£…å¥½äº†å„ç§æ± åŒ–å±‚ï¼Œå¸¸è§çš„æœ‰æœ€å¤§æ± åŒ–ï¼ˆMaxPoolï¼‰å’Œå¹³å‡æ± åŒ–ï¼ˆAvgPool)ã€‚</p>
        </div>
      </div>
    </div>

<h2 id="å®‰è£…-pytorch-cpu-ç‰ˆæœ¬"><a href="#å®‰è£…-pytorch-cpu-ç‰ˆæœ¬" class="headerlink" title="å®‰è£… pytorch cpu ç‰ˆæœ¬"></a>å®‰è£… pytorch cpu ç‰ˆæœ¬</h2><p><a href="https://pytorch.org/get-started/previous-versions/">https://pytorch.org/get-started/previous-versions/</a></p>

    <div class="fold">
      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-95c8a4aa" role="button" aria-expanded="false" aria-controls="collapse-95c8a4aa">
        <div class="fold-arrow">â–¶</div>ç‚¹å‡»æ­¤å¤„æŸ¥çœ‹æ­¥éª¤
      </div>
      <div class="fold-collapse collapse" id="collapse-95c8a4aa">
        <div class="fold-content">
          <p><img src="/img/post_pics/ai/Pytorch.png" srcset="/img/loading.gif" lazyload alt="Pytorch"></p><p><strong>å®‰è£… Anaconda. ä¸‹è½½åœ°å€:</strong> <a href="https://www.anaconda.com/download">https://www.anaconda.com/download</a></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># For example, Ubuntu</span><br>$ wget https://repo.anaconda.com/archive/Anaconda3-2024.02-1-Linux-x86_64.sh<br>$ <span class="hljs-built_in">chmod</span> +x Anaconda3-2024.02-1-Linux-x86_64.sh<br>$ ./Anaconda3-2024.02-1-Linux-x86_64.sh<br>$ <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;export PATH=\&quot;/root/anaconda3/bin\&quot;:\$PATH&quot;</span> &gt;&gt; ~/.bashrc   <span class="hljs-comment"># Check the path</span><br>$ <span class="hljs-built_in">source</span> ~/.bashrc<br><br><span class="hljs-comment"># Check if it is installed successfully:</span><br>$ conda --version<br>conda 24.1.2<br></code></pre></td></tr></table></figure><p><strong>æ¢æº</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># Reference https://blog.csdn.net/adreammaker/article/details/123396951</span><br>$ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/<br>$ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/<br>$ conda config --<span class="hljs-built_in">set</span> show_channel_urls <span class="hljs-built_in">yes</span><br></code></pre></td></tr></table></figure><p><strong>åˆ›å»ºPytorchè™šæ‹Ÿç¯å¢ƒ</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">conda create -n torch-1.6  python=3.6.13<br></code></pre></td></tr></table></figure><details><summary>åˆ›å»ºè¿‡ç¨‹çš„log</summary><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ conda create -n torch-1.6  python=3.6.13<br>Channels:<br> - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main<br> - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free<br> - defaults<br>Platform: linux-64<br>Collecting package metadata (repodata.json): <span class="hljs-keyword">done</span><br>Solving environment: <span class="hljs-keyword">done</span><br><br><span class="hljs-comment">## Package Plan ##</span><br><br>  environment location: /home/shenjianliang/anaconda3/envs/torch-1.6<br><br>  added / updated specs:<br>    - python=3.6.13<br><br><br>The following packages will be downloaded:<br><br>    package                    |            build<br>    ---------------------------|-----------------<br>    certifi-2021.5.30          |   py36h06a4308_0         139 KB  https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main<br>    libffi-3.3                 |       he6710b0_2          50 KB  https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main<br>    openssl-1.1.1w             |       h7f8727e_0         3.7 MB  https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main<br>    pip-21.2.2                 |   py36h06a4308_0         1.8 MB  https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main<br>    python-3.6.13              |       h12debd9_1        32.5 MB  https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main<br>    setuptools-58.0.4          |   py36h06a4308_0         788 KB  https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main<br>    wheel-0.37.1               |     pyhd3eb1b0_0          33 KB  https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main<br>    ------------------------------------------------------------<br>                                           Total:        39.0 MB<br><br>The following NEW packages will be INSTALLED:<br><br>  _libgcc_mutex      anaconda/pkgs/main/linux-64::_libgcc_mutex-0.1-main<br>  _openmp_mutex      anaconda/pkgs/main/linux-64::_openmp_mutex-5.1-1_gnu<br>  ca-certificates    anaconda/pkgs/main/linux-64::ca-certificates-2024.3.11-h06a4308_0<br>  certifi            anaconda/pkgs/main/linux-64::certifi-2021.5.30-py36h06a4308_0<br>  ld_impl_linux-64   anaconda/pkgs/main/linux-64::ld_impl_linux-64-2.38-h1181459_1<br>  libffi             anaconda/pkgs/main/linux-64::libffi-3.3-he6710b0_2<br>  libgcc-ng          anaconda/pkgs/main/linux-64::libgcc-ng-11.2.0-h1234567_1<br>  libgomp            anaconda/pkgs/main/linux-64::libgomp-11.2.0-h1234567_1<br>  libstdcxx-ng       anaconda/pkgs/main/linux-64::libstdcxx-ng-11.2.0-h1234567_1<br>  ncurses            anaconda/pkgs/main/linux-64::ncurses-6.4-h6a678d5_0<br>  openssl            anaconda/pkgs/main/linux-64::openssl-1.1.1w-h7f8727e_0<br>  pip                anaconda/pkgs/main/linux-64::pip-21.2.2-py36h06a4308_0<br>  python             anaconda/pkgs/main/linux-64::python-3.6.13-h12debd9_1<br>  readline           anaconda/pkgs/main/linux-64::readline-8.2-h5eee18b_0<br>  setuptools         anaconda/pkgs/main/linux-64::setuptools-58.0.4-py36h06a4308_0<br>  sqlite             anaconda/pkgs/main/linux-64::sqlite-3.45.3-h5eee18b_0<br>  tk                 anaconda/pkgs/main/linux-64::tk-8.6.14-h39e8969_0<br>  wheel              anaconda/pkgs/main/noarch::wheel-0.37.1-pyhd3eb1b0_0<br>  xz                 anaconda/pkgs/main/linux-64::xz-5.4.6-h5eee18b_1<br>  zlib               anaconda/pkgs/main/linux-64::zlib-1.2.13-h5eee18b_1<br><br><br>Proceed ([y]/n)? y<br><br><br>Downloading and Extracting Packages:<br><br>Preparing transaction: <span class="hljs-keyword">done</span><br>Verifying transaction: <span class="hljs-keyword">done</span><br>Executing transaction: <span class="hljs-keyword">done</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment"># To activate this environment, use</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#     $ conda activate torch-1.6</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment"># To deactivate an active environment, use</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#     $ conda deactivate</span><br></code></pre></td></tr></table></figure></details><p><strong>æ¿€æ´»ç¯å¢ƒ</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">conda activate torch-1.6<br></code></pre></td></tr></table></figure><p><strong>å®‰è£…Pytorch 1.6</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">conda install pytorch==1.6.0 torchvision==0.7.0 -c pytorch<br></code></pre></td></tr></table></figure><details><summary>å®‰è£…çš„log</summary><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ conda install pytorch==1.6.0 torchvision==0.7.0 -c pytorch<br>Channels:<br> - pytorch<br> - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main<br> - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free<br> - defaults<br>Platform: linux-64<br>Collecting package metadata (repodata.json): <span class="hljs-keyword">done</span><br>Solving environment: <span class="hljs-keyword">done</span><br><br><span class="hljs-comment">## Package Plan ##</span><br><br>  environment location: /home/shenjianliang/anaconda3/envs/torch-1.6<br><br>  added / updated specs:<br>    - pytorch==1.6.0<br>    - torchvision==0.7.0<br><br><br>The following packages will be downloaded:<br><br>    package                    |            build<br>    ---------------------------|-----------------<br>    cudatoolkit-10.2.89        |       hfd86e86_1       365.1 MB  https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main<br>    giflib-5.2.1               |       h5eee18b_3          80 KB  https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main<br>    intel-openmp-2022.1.0      |    h9e868ea_3769         4.5 MB  https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main<br>    libgfortran-ng-7.5.0       |      ha8ba4b0_17          22 KB  https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main<br>    libgfortran4-7.5.0         |      ha8ba4b0_17         995 KB  https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main<br>    libwebp-1.2.4              |       h11a3e52_1          86 KB  https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main<br>    libwebp-base-1.2.4         |       h5eee18b_1         376 KB  https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main<br>    mkl-2022.1.0               |     hc2b9512_224       129.7 MB  https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main<br>    ninja-1.10.2               |       h06a4308_5           8 KB  https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main<br>    ninja-base-1.10.2          |       hd09550d_5         109 KB  https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main<br>    numpy-1.14.2               |   py36hdbf6ddf_0         3.2 MB  https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main<br>    olefile-0.46               |     pyhd3eb1b0_0          34 KB  https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main<br>    pillow-8.3.1               |   py36h5aabda8_0         638 KB  https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main<br>    pytorch-1.6.0              |py3.6_cuda10.2.89_cudnn7.6.5_0       537.3 MB  pytorch<br>    torchvision-0.7.0          |       py36_cu102        11.0 MB  pytorch<br>    ------------------------------------------------------------<br>                                           Total:        1.03 GB<br><br>The following NEW packages will be INSTALLED:<br><br>  blas               anaconda/pkgs/main/linux-64::blas-1.0-mkl<br>  cudatoolkit        anaconda/pkgs/main/linux-64::cudatoolkit-10.2.89-hfd86e86_1<br>  freetype           anaconda/pkgs/main/linux-64::freetype-2.12.1-h4a9f257_0<br>  giflib             anaconda/pkgs/main/linux-64::giflib-5.2.1-h5eee18b_3<br>  intel-openmp       anaconda/pkgs/main/linux-64::intel-openmp-2022.1.0-h9e868ea_3769<br>  jpeg               anaconda/pkgs/main/linux-64::jpeg-9e-h5eee18b_1<br>  lcms2              anaconda/pkgs/main/linux-64::lcms2-2.12-h3be6417_0<br>  lerc               anaconda/pkgs/main/linux-64::lerc-3.0-h295c915_0<br>  libdeflate         anaconda/pkgs/main/linux-64::libdeflate-1.17-h5eee18b_1<br>  libgfortran-ng     anaconda/pkgs/main/linux-64::libgfortran-ng-7.5.0-ha8ba4b0_17<br>  libgfortran4       anaconda/pkgs/main/linux-64::libgfortran4-7.5.0-ha8ba4b0_17<br>  libpng             anaconda/pkgs/main/linux-64::libpng-1.6.39-h5eee18b_0<br>  libtiff            anaconda/pkgs/main/linux-64::libtiff-4.5.1-h6a678d5_0<br>  libwebp            anaconda/pkgs/main/linux-64::libwebp-1.2.4-h11a3e52_1<br>  libwebp-base       anaconda/pkgs/main/linux-64::libwebp-base-1.2.4-h5eee18b_1<br>  lz4-c              anaconda/pkgs/main/linux-64::lz4-c-1.9.4-h6a678d5_1<br>  mkl                anaconda/pkgs/main/linux-64::mkl-2022.1.0-hc2b9512_224<br>  ninja              anaconda/pkgs/main/linux-64::ninja-1.10.2-h06a4308_5<br>  ninja-base         anaconda/pkgs/main/linux-64::ninja-base-1.10.2-hd09550d_5<br>  numpy              anaconda/pkgs/main/linux-64::numpy-1.14.2-py36hdbf6ddf_0<br>  olefile            anaconda/pkgs/main/noarch::olefile-0.46-pyhd3eb1b0_0<br>  pillow             anaconda/pkgs/main/linux-64::pillow-8.3.1-py36h5aabda8_0<br>  pytorch            pytorch/linux-64::pytorch-1.6.0-py3.6_cuda10.2.89_cudnn7.6.5_0<br>  torchvision        pytorch/linux-64::torchvision-0.7.0-py36_cu102<br>  zstd               anaconda/pkgs/main/linux-64::zstd-1.5.5-hc292b87_2<br><br><br>Proceed ([y]/n)? y<br><br><br>Downloading and Extracting Packages:<br><br>Preparing transaction: <span class="hljs-keyword">done</span><br>Verifying transaction: <span class="hljs-keyword">done</span><br>Executing transaction: <span class="hljs-keyword">done</span><br></code></pre></td></tr></table></figure></details><p><strong>Condaåˆ é™¤ç¯å¢ƒ</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># é€€å‡ºå½“å‰ç¯å¢ƒ</span><br>$ conda deactivate<br><br><span class="hljs-comment"># åˆ—å‡ºå½“å‰env</span><br>$ conda <span class="hljs-built_in">env</span> list<br><span class="hljs-comment"># conda environments:</span><br><span class="hljs-comment">#</span><br>base                     /home/shenjianliang/anaconda3<br>torch-1.6             *  /home/shenjianliang/anaconda3/envs/torch-1.6<br><br><span class="hljs-comment"># åˆ é™¤</span><br>$ conda <span class="hljs-built_in">env</span> remove -p /home/shenjianliang/anaconda3/envs/torch-1.6<br></code></pre></td></tr></table></figure><p><strong>ä¸ç”¨Anacondaï¼Œä½¿ç”¨pythonè™šæ‹Ÿenv</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">sudo</span> apt-get install python3-venv<br>python3.6 -m venv myenv<br><span class="hljs-built_in">source</span> myenv/bin/activate<br><br>pip install torch==1.6.0+cpu torchvision==0.7.0+cpu -f https://download.pytorch.org/whl/torch_stable.html<br></code></pre></td></tr></table></figure>
        </div>
      </div>
    </div>

<h2 id="å®‰è£…-pytorch-cuda-ç‰ˆæœ¬"><a href="#å®‰è£…-pytorch-cuda-ç‰ˆæœ¬" class="headerlink" title="å®‰è£… pytorch cuda ç‰ˆæœ¬"></a>å®‰è£… pytorch cuda ç‰ˆæœ¬</h2><p>åœ¨RTX4070S windowsä¸­é…ç½®WSLç›¸å…³çš„AIç¯å¢ƒï¼ŒåŒ…æ‹¬CUDAï¼ŒPyTorchï¼ŒCudnnç­‰</p>

    <div class="fold">
      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-0142a643" role="button" aria-expanded="false" aria-controls="collapse-0142a643">
        <div class="fold-arrow">â–¶</div>æ­¥éª¤
      </div>
      <div class="fold-collapse collapse" id="collapse-0142a643">
        <div class="fold-content">
          <p><strong>å®‰è£…WSL&#x2F;Docker&#x2F;Nvidiaï¼š</strong><br><a href="https://blog.csdn.net/ndscvipuser/article/details/136610169">Windows ä¸‹è®© Docker Desktop å…³è”ä¸Š NVidia GPU</a><br><a href="https://blog.csdn.net/dghcs18/article/details/134244426">å¦‚ä½•æŸ¥çœ‹wslæ˜¯wsl1è¿˜æ˜¯wsl2</a><br><a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html">Nvidia WSLå®˜æ–¹æŒ‡å¼•</a><br><a href="https://blog.csdn.net/weixin_55274216/article/details/137630257">linuxä¸Šcudaç›¸å…³åŒ…ä¸opencvåŠç›¸å…³æ¨¡å—å®‰è£…ï¼ˆwsl+ubuntu22.04ï¼‰</a></p><blockquote><p>æ³¨æ„ï¼šWSLä¸éœ€è¦è£…cudaé©±åŠ¨ï¼Œä¸¢åœ¨win hostå®‰è£…ï¼Œæ¯”å¦‚Geforceç­‰é©±åŠ¨è½¯ä»¶ï¼Œå®‰è£…å®Œæˆåè¿è¡Œ<code>nvidia-smi</code></p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># Powershellä¸­æµ‹è¯•</span><br>docker run --<span class="hljs-built_in">rm</span> --runtime=nvidia --gpus all ubuntu nvidia-smi<br></code></pre></td></tr></table></figure><p>Docker Desktopä¸­çš„è®¾ç½®ï¼š</p><p><img src="/img/post_pics/ai/docker_set1.png" srcset="/img/loading.gif" lazyload alt="1"><br><img src="/img/post_pics/ai/docker_set2.png" srcset="/img/loading.gif" lazyload alt="2"></p><p>æµ‹è¯•ç»“æœï¼š</p><p><img src="/img/post_pics/ai/docker.png" srcset="/img/loading.gif" lazyload alt="3"></p><p>WSLä¸­æµ‹è¯•ï¼š</p><p><img src="/img/post_pics/ai/wsl.png" srcset="/img/loading.gif" lazyload alt="4"></p><p>å®‰è£…<a href="https://developer.nvidia.cn/cuda-downloads">cuda toolkit</a></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs bash">wget https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-wsl-ubuntu.pin<br><span class="hljs-built_in">sudo</span> <span class="hljs-built_in">mv</span> cuda-wsl-ubuntu.pin /etc/apt/preferences.d/cuda-repository-pin-600<br>wget https://developer.download.nvidia.com/compute/cuda/12.4.1/local_installers/cuda-repo-wsl-ubuntu-12-4-local_12.4.1-1_amd64.deb<br><span class="hljs-built_in">sudo</span> dpkg -i cuda-repo-wsl-ubuntu-12-4-local_12.4.1-1_amd64.deb<br><span class="hljs-built_in">sudo</span> <span class="hljs-built_in">cp</span> /var/cuda-repo-wsl-ubuntu-12-4-<span class="hljs-built_in">local</span>/cuda-*-keyring.gpg /usr/share/keyrings/<br><span class="hljs-built_in">sudo</span> apt-get update<br><span class="hljs-built_in">sudo</span> apt-get -y install cuda-toolkit-12-4<br><br><span class="hljs-comment"># ~/.bashrc</span><br><span class="hljs-built_in">export</span> LD_LIBRARY_PATH=/usr/local/cuda/lib64<br><span class="hljs-built_in">export</span> PATH=<span class="hljs-variable">$PATH</span>:/usr/local/cuda/bin<br><br>nvcc -V<br>nvcc: NVIDIA (R) Cuda compiler driver<br>Copyright (c) 2005-2024 NVIDIA Corporation<br>Built on Thu_Mar_28_02:18:24_PDT_2024<br>Cuda compilation tools, release 12.4, V12.4.131<br>Build cuda_12.4.r12.4/compiler.34097967_0<br></code></pre></td></tr></table></figure><p><strong>å®‰è£…Conda</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment">#åˆ›å»ºç¯å¢ƒ</span><br>conda init<br>conda create -n torch-gpu  python=3.9<br>conda activate torch-gpu<br><br><span class="hljs-comment">#æ¢æºï¼Œå‚è€ƒhttps://blog.csdn.net/watermelon1123/article/details/88122020</span><br>conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/<br>conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/<br>conda config --<span class="hljs-built_in">set</span> show_channel_urls <span class="hljs-built_in">yes</span><br><br><span class="hljs-comment">#å®‰è£…torchï¼Œå‘½ä»¤åœ¨ https://pytorch.org/ å¯»æ‰¾</span><br>conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch-nightly -c nvidia<br><br><span class="hljs-comment"># ~/.bashrc</span><br>conda activate torch-gpu<br></code></pre></td></tr></table></figure><p><strong>å®‰è£…cuDNNï¼š<a href="https://developer.nvidia.com/cudnn-downloads">https://developer.nvidia.com/cudnn-downloads</a></strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash">wget https://developer.download.nvidia.com/compute/cudnn/9.2.0/local_installers/cudnn-local-repo-ubuntu2004-9.2.0_1.0-1_amd64.deb<br><span class="hljs-built_in">sudo</span> dpkg -i cudnn-local-repo-ubuntu2004-9.2.0_1.0-1_amd64.deb<br><span class="hljs-built_in">sudo</span> <span class="hljs-built_in">cp</span> /var/cudnn-local-repo-ubuntu2004-9.2.0/cudnn-*-keyring.gpg /usr/share/keyrings/<br><span class="hljs-built_in">sudo</span> apt-get update<br><span class="hljs-built_in">sudo</span> apt-get -y install cudnn-cuda-12<br><br><span class="hljs-comment"># æŸ¥çœ‹ç‰ˆæœ¬</span><br><span class="hljs-built_in">cat</span> /usr/include/cudnn_version.h | grep CUDNN_MAJOR -A 2<br></code></pre></td></tr></table></figure>
        </div>
      </div>
    </div>

<h2 id="pytorch-book-vscode-ç¯å¢ƒé…ç½®"><a href="#pytorch-book-vscode-ç¯å¢ƒé…ç½®" class="headerlink" title="pytorch book vscode ç¯å¢ƒé…ç½®"></a>pytorch book vscode ç¯å¢ƒé…ç½®</h2>
    <div class="fold">
      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-a474e0a9" role="button" aria-expanded="false" aria-controls="collapse-a474e0a9">
        <div class="fold-arrow">â–¶</div>æ­¥éª¤
      </div>
      <div class="fold-collapse collapse" id="collapse-a474e0a9">
        <div class="fold-content">
          <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">git <span class="hljs-built_in">clone</span> git@github.com:chenyuntc/pytorch-book.git<br></code></pre></td></tr></table></figure><p>VScodeå®‰è£…æ’ä»¶</p><p><img src="/img/post_pics/ai/torch-book-extension.png" srcset="/img/loading.gif" lazyload></p><p>æ­¤æ—¶æ‰“å¼€ä»»æ„ä¸€ä¸ªnoteå¯ä»¥çœ‹åˆ°ä»£ç å˜æˆå¯ä»¥æ‰§è¡Œçš„æ¡†äº†ï¼š</p><p><img src="/img/post_pics/ai/vscode-load-python-1.png" srcset="/img/loading.gif" lazyload></p><p>ä½†æ˜¯ä¼šæ˜¾ç¤ºtorchæœªå¯¼å…¥ï¼Œç‚¹å‡»å·¦ä¾§çš„æ‰§è¡Œä¸‰è§’å½¢æŒ‰é’®ï¼Œä¼šæç¤ºé€‰æ‹©å®‰è£…å¿…è¦çš„æ’ä»¶ï¼Œå®‰è£…å®Œæˆåå†æ¬¡ç‚¹å‡»ï¼Œä¼šæç¤ºé€‰æ‹©pythonç‰ˆæœ¬</p><p><img src="/img/post_pics/ai/vscode-load-python-11.png" srcset="/img/loading.gif" lazyload></p><p>é€‰æ‹©pythonç¯å¢ƒï¼Œæ‰¾åˆ°condaè·¯å¾„ä¸‹çš„pythonè§£é‡Šå™¨</p><p><img src="/img/post_pics/ai/vscode-load-python-111.png" srcset="/img/loading.gif" lazyload></p><p>å†æ¬¡ç‚¹å‡»å·¦ä¾§è¿è¡Œï¼Œå¼¹å‡ºè¦å®‰è£…pykernelåŒ…ï¼Œç‚¹å‡»å®‰è£…å®Œæˆåï¼Œå¯ä»¥åœ¨å³ä¸Šè§’çœ‹åˆ°ç¯å¢ƒå’Œpythonç‰ˆæœ¬ï¼Œä¹Ÿå¯ä»¥ç‚¹å‡»æ­¤å¤„ç»§ç»­æ›´æ¢ç¯å¢ƒã€‚</p>
        </div>
      </div>
    </div>

<h2 id="ç¤ºä¾‹"><a href="#ç¤ºä¾‹" class="headerlink" title="ç¤ºä¾‹"></a>ç¤ºä¾‹</h2><h3 id="çº¿æ€§å›å½’"><a href="#çº¿æ€§å›å½’" class="headerlink" title="çº¿æ€§å›å½’"></a>çº¿æ€§å›å½’</h3><p>æ¢¯åº¦ä¸‹é™ç®—æ³•å’Œauto gradè‡ªåŠ¨æ±‚è§£æ¢¯åº¦å‡½æ•°ï¼Œå‚è€ƒ <a href="https://github.com/chenyuntc/pytorch-book"><strong>ã€Šæ·±åº¦å­¦ä¹ æ¡†æ¶PyTorchï¼šå…¥é—¨ä¸å®æˆ˜ã€‹ä»£ç </strong></a> å°è¯•ç‰›åˆ€: ç”¨autogradå®ç°çº¿æ€§å›å½’ã€‚</p>
<h3 id="fashion-mnist-æ‰‹å†™æ•°å­—åˆ†ç±»"><a href="#fashion-mnist-æ‰‹å†™æ•°å­—åˆ†ç±»" class="headerlink" title="fashion mnist æ‰‹å†™æ•°å­—åˆ†ç±»"></a>fashion mnist æ‰‹å†™æ•°å­—åˆ†ç±»</h3><p>å‚è€ƒPytorchæ•™ç¨‹: <a href="https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html">Quick Start</a></p>

    <div class="fold">
      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-bca7c96c" role="button" aria-expanded="false" aria-controls="collapse-bca7c96c">
        <div class="fold-arrow">â–¶</div>è®­ç»ƒæ­¥éª¤
      </div>
      <div class="fold-collapse collapse" id="collapse-bca7c96c">
        <div class="fold-content">
          <ol><li>ä¸‹è½½æ•°æ®é›†</li><li>æ•°æ®é¢„å¤„ç†ç­‰<a href="https://pytorch.org/tutorials/beginner/basics/data_tutorial.html">Data Tutorial</a></li><li>å®šä¹‰modelï¼Œç±»å‹ã€å±‚ã€å‰å‘å‡½æ•°å’ŒæŸå¤±è®¡ç®—å‡½æ•°ï¼Œå¹¶ä¼ é€’è‡³deviceï¼Œå¦‚CPUæˆ–è€…CUDAï¼Œ<a href="https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html">Build Model</a><ol><li><a href="https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html">Sequential</a>ï¼Œæ„å»ºè¿ç»­çš„å±‚<a href="https://blog.csdn.net/dss_dssssd/article/details/82980222">pytorchç³»åˆ— nn.Sequentialè®²è§£</a></li><li>ä¸€äº›å±‚çº§çš„ç®€å•ä»‹ç»ï¼Œ<a href="https://yey.world/2020/12/16/Pytorch-13/">nn ç½‘ç»œå±‚ï¼šæ± åŒ–å±‚ã€çº¿æ€§å±‚å’Œæ¿€æ´»å‡½æ•°å±‚</a><ol><li><a href="https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html">ReLU</a></li><li><a href="https://pytorch.org/docs/stable/generated/torch.nn.Linear.html">Linear</a></li></ol></li></ol></li><li>ä¼˜åŒ–æŸå¤±è®¡ç®—ï¼Œ<a href="https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html">Optimization Tutorials</a><ol><li><a href="https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html">äº¤å‰ç†µæŸå¤±Cross Entropy Loss</a>ï¼Œå‚è€ƒ<a href="https://blog.csdn.net/chao_shine/article/details/89925762">äº¤å‰ç†µæŸå¤±å‡½æ•°åŸç†åŠPytorchä»£ç ç®€ä»‹</a></li><li><a href="https://zhuanlan.zhihu.com/p/78622301">Pytorchä¸­å¸¸ç”¨çš„å››ç§ä¼˜åŒ–å™¨SGDã€Momentumã€RMSPropã€Adam</a><ol><li><a href="https://pytorch.org/docs/stable/generated/torch.optim.SGD.html">SGD</a></li></ol></li></ol></li><li>è®­ç»ƒï¼Œå¯¼å…¥æ•°æ®ï¼Œè®¡ç®—æŸå¤±ï¼Œè°ƒç”¨å‰å‘å‡½æ•°</li><li>æµ‹è¯•ï¼Œå¯¹æµ‹è¯•é›†é¢„æµ‹ï¼Œè®¡ç®—é¢„æµ‹ç»“æœäº‰å–ç‡</li><li>ä¿å­˜æ¨¡å‹ï¼Œ<a href="https://pytorch.org/tutorials/beginner/basics/saveloadrun_tutorial.html">Save &amp; Load &amp; Run</a></li></ol>
        </div>
      </div>
    </div>


    <div class="fold">
      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-2063547c" role="button" aria-expanded="false" aria-controls="collapse-2063547c">
        <div class="fold-arrow">â–¶</div>æµ‹è¯•æ¨¡å‹
      </div>
      <div class="fold-collapse collapse" id="collapse-2063547c">
        <div class="fold-content">
          <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> datasets<br><span class="hljs-keyword">from</span> torchvision.transforms <span class="hljs-keyword">import</span> ToTensor<br><br>test_data = datasets.FashionMNIST(<br>    root=<span class="hljs-string">&quot;data&quot;</span>,<br>    train=<span class="hljs-literal">False</span>,<br>    download=<span class="hljs-literal">True</span>,<br>    transform=ToTensor(),<br>)<br><br>device = (<br>    <span class="hljs-string">&quot;cuda&quot;</span><br>    <span class="hljs-keyword">if</span> torch.cuda.is_available()<br>    <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;mps&quot;</span><br>    <span class="hljs-keyword">if</span> torch.backends.mps.is_available()<br>    <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span><br>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Using <span class="hljs-subst">&#123;device&#125;</span> device&quot;</span>)<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">NeuralNetwork</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-variable language_">self</span>.flatten = nn.Flatten()<br>        <span class="hljs-variable language_">self</span>.linear_relu_stack = nn.Sequential(<br>            nn.Linear(<span class="hljs-number">28</span>*<span class="hljs-number">28</span>, <span class="hljs-number">512</span>),<br>            nn.ReLU(),<br>            nn.Linear(<span class="hljs-number">512</span>, <span class="hljs-number">512</span>),<br>            nn.ReLU(),<br>            nn.Linear(<span class="hljs-number">512</span>, <span class="hljs-number">10</span>)<br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = <span class="hljs-variable language_">self</span>.flatten(x)<br>        logits = <span class="hljs-variable language_">self</span>.linear_relu_stack(x)<br>        <span class="hljs-keyword">return</span> logits<br><br>model = NeuralNetwork().to(device)<br>model.load_state_dict(torch.load(<span class="hljs-string">&quot;model.pth&quot;</span>))<br><br><br>classes = [<br>    <span class="hljs-string">&quot;T-shirt/top&quot;</span>,<br>    <span class="hljs-string">&quot;Trouser&quot;</span>,<br>    <span class="hljs-string">&quot;Pullover&quot;</span>,<br>    <span class="hljs-string">&quot;Dress&quot;</span>,<br>    <span class="hljs-string">&quot;Coat&quot;</span>,<br>    <span class="hljs-string">&quot;Sandal&quot;</span>,<br>    <span class="hljs-string">&quot;Shirt&quot;</span>,<br>    <span class="hljs-string">&quot;Sneaker&quot;</span>,<br>    <span class="hljs-string">&quot;Bag&quot;</span>,<br>    <span class="hljs-string">&quot;Ankle boot&quot;</span>,<br>]<br><br>model.<span class="hljs-built_in">eval</span>()<br><br>x, y = test_data[<span class="hljs-number">1</span>][<span class="hljs-number">0</span>], test_data[<span class="hljs-number">1</span>][<span class="hljs-number">1</span>]<br><span class="hljs-keyword">with</span> torch.no_grad():<br>    x = x.to(device)<br>    pred = model(x)<br>    predicted, actual = classes[pred[<span class="hljs-number">0</span>].argmax(<span class="hljs-number">0</span>)], classes[y]<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Predicted: &quot;<span class="hljs-subst">&#123;predicted&#125;</span>&quot;, Actual: &quot;<span class="hljs-subst">&#123;actual&#125;</span>&quot;&#x27;</span>)<br></code></pre></td></tr></table></figure>
        </div>
      </div>
    </div>

<h3 id="cifar-10"><a href="#cifar-10" class="headerlink" title="cifar 10"></a>cifar 10</h3><p>å‚è€ƒ <a href="https://github.com/chenyuntc/pytorch-book"><strong>ã€Šæ·±åº¦å­¦ä¹ æ¡†æ¶PyTorchï¼šå…¥é—¨ä¸å®æˆ˜ã€‹ä»£ç </strong></a> 2.2.4 å°è¯•ç‰›åˆ€ï¼šCIFAR-10åˆ†ç±»ã€‚</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/GPU/" class="category-chain-item">GPU</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/CUDA/" class="print-no-link">#CUDA</a>
      
        <a href="/tags/GPU/" class="print-no-link">#GPU</a>
      
        <a href="/tags/Algorithm/" class="print-no-link">#Algorithm</a>
      
        <a href="/tags/AI/" class="print-no-link">#AI</a>
      
        <a href="/tags/Pytorch/" class="print-no-link">#Pytorch</a>
      
    </div>
  
</div>


              

              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2024/07/02/Security/Nvidia-HCC-Driver-Code/" title="æœºå¯†è®¡ç®—: HCC é©±åŠ¨ä»£ç ">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">æœºå¯†è®¡ç®—: HCC é©±åŠ¨ä»£ç </span>
                        <span class="visible-mobile">Previous</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2024/06/20/GPU/DIY-PC/" title="è£…æœºè®°å½•">
                        <span class="hidden-mobile">è£…æœºè®°å½•</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>Table of Contents</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  









    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">Keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Tech Odyssey</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>2024</span></a> 
    </div>
  
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>





<!-- ä¸»é¢˜çš„å¯åŠ¨é¡¹ï¼Œå°†å®ƒä¿æŒåœ¨æœ€åº•éƒ¨ -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">Blog works best with JavaScript enabled</div>
  </noscript>
<!-- hexo injector body_end start --><script data-pjax src="https://unpkg.com/oh-my-live2d"></script><script>const oml2d = OML2D.loadOml2d({dockedPosition:"left",mobileDisplay:false,models:[{"path":"/live2d-models/models/umaru/model.json","position":[100,30],"scale":0.25,"stageStyle":{"width":400,"height":470}},{"path":"/live2d-models/models/kobayaxi/model.json","position":[30,0],"scale":0.3,"stageStyle":{"width":400}},{"path":"/live2d-models/models/bilibili-22/index.json","position":[0,30],"scale":0.35,"stageStyle":{"width":400}},{"path":"/live2d-models/models/bilibili-33/index.json","position":[0,30],"scale":0.35,"stageStyle":{"width":400}}],parentElement:document.body,primaryColor:"#7f6f6c",tips:{style: {"left":"calc(50%)","top":"-50px"},idleTips:{interval:150}}});</script><!-- hexo injector body_end end --></body>
</html>
